---
title: "Paper I read"
tags:
  - deep learning
---

{% include toc title="Unique Title" icon="file-text" %}

# Paper-I-read
This repo contains scientific paper I read as a reminder to myself. Hope this is helpful to you too.

# Time line

## 2017

### Christmas reading list

[COMPARISON OF BATCH NORMALIZATION AND
WEIGHT NORMALIZATION ALGORITHMS FOR THE
LARGE-SCALE IMAGE CLASSIFICATION](https://arxiv.org/pdf/1709.08145.pdf)

[House3D: A Rich and Realistic 3D Environment](http://embodiedqa.org/paper.pdf)

[CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning](http://vision.stanford.edu/pdf/johnson2017cvpr.pdf)

[Extreme Learning Machine for Multilayer Perceptron](https://pdfs.semanticscholar.org/2878/d9936f494ed7d0c8aec47e9bcc5e51609f9a.pdf)

[Deep Reinforcement Learning that Matters](https://arxiv.org/pdf/1709.06560.pdf)

[Run, skeleton, run: skeletal model in a physics-based simulation](https://arxiv.org/pdf/1711.06922.pdf)

[Curiosity-driven Exploration by Self-supervised Prediction (Intrinsic Curiosity Module)](https://arxiv.org/pdf/1705.05363.pdf)

[Neural Map: Structured Memory For Deep Reinforcement Learning (Useful to vMWM)](https://arxiv.org/pdf/1702.08360.pdf)

[GPU Kernels for Block-Sparse Weights (OpenAI train bigger DNN)](https://s3-us-west-2.amazonaws.com/openai-assets/blocksparse/blocksparsepaper.pdf)

[Meta Learning Shared Hierarchies(OpenAI choose operand)](https://arxiv.org/pdf/1710.09767.pdf)

[Sim-to-Real Transfer of Robotic Control with Dynamics Randomization (OpenAI randomnized environment to better generalization)](https://arxiv.org/pdf/1710.06537.pdf)

[Asymmetric Actor Critic for Image-Based Robot Learning (OpenAI techer-student critic learning)](https://arxiv.org/pdf/1710.06542.pdf)

[Ai Safety Gridworld (DeepMind "Performance function" hidden goal)](https://arxiv.org/pdf/1711.09883.pdf)

[Population Based Training of Neural Networks (DeepMind Baysian hyperparameter Optimization-Explore,exploit)](https://arxiv.org/abs/1711.09846)

[Learning Explanatory Rules from Noisy Data(Differentiable Inductive Logic framework)](https://arxiv.org/pdf/1711.04574.pdf)

[Neural Discrete Representation Learning (Vector Quantised Variational AutoEncoder)](https://arxiv.org/pdf/1711.00937.pdf)

[A Unified Game-Theoretic Approach to
Multiagent Reinforcement Learning](https://arxiv.org/pdf/1711.00832.pdf)

### Thanksgiving reading list

[ImageNet Training in Minutes
(featureing Intel's CPU distributed DNN training platform)](https://arxiv.org/pdf/1709.05011.pdf)

[Hierarchical Representations For Efficient Architecture Search (ES designd network architecture)](https://arxiv.org/pdf/1711.00436.pdf)

[Understanding Deep Learning Requires Rethinking Generalization (DNN shatter dataset)](https://arxiv.org/pdf/1611.03530.pdf)

[Dynamic Routing Between Capsules (Pixel to coord with unsupervised routing)](https://arxiv.org/pdf/1710.09829.pdf)

### RL

[Neural Combinatory Optimization with Reinforcment Learning (RL TSP)](https://arxiv.org/pdf/1611.09940.pdf)

[Mastering the game of Go without human knowledge (AlphaGO Zero)](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)

[Rainbow: Combining Improvements in Deep Reinforcement Learning (Rainbow 6)](https://yhyu13.github.io/DeepMind-Rainbow/)

[Reverse Curriculum Generation for Reinforcement Learning (Reward guiding)](https://arxiv.org/pdf/1707.05300.pdf)

[Automatic Goal Generation for Reinforcement Learning Agents (goal GAN)](https://arxiv.org/pdf/1705.06366.pdf)

[Learning with Oppent-learning Awarness (LOLA)](https://arxiv.org/pdf/1709.04326.pdf)

[Evolution Strategies as a
Scalable Alternative to Reinforcement Learning (distributed ES)](https://arxiv.org/pdf/1703.03864.pdf)

### Architecture

[Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech
Recognition (Res-LSTM)](https://arxiv.org/pdf/1701.03360.pdf)

[Learning Hierarchical Information Flow with Recurrent Neural Modules (ThalNet)](https://pdfs.semanticscholar.org/76d1/9efb925b33e67d93c94a9cab242889186485.pdf)

[Learning human behaviors from motion capture by adversarial imitation (GAIL)](https://arxiv.org/pdf/1707.02201.pdf)

### Neuroscience

[Bridging the Gaps Between Residual Learning,
Recurrent Neural Networks and Visual Cortex (ResNet~=recurrent network)](https://arxiv.org/pdf/1604.03640.pdf)

[Neuroscience inspired A.I. (Survey)](http://www.cell.com/neuron/abstract/S0896-6273(17)30509-3)

### Others

[On the Origin of Deep Learning (Survey)](https://arxiv.org/pdf/1702.07800.pdf)

## 2016

[Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)

[Deep Residual Networks with Exponential Linear Unit](https://arxiv.org/pdf/1604.04112.pdf)

[Residual Networks Behave Like Ensembles of
Relatively Shallow Networks](https://arxiv.org/pdf/1605.06431.pdf)

[Toward an Integration of Deep Learning and Neuroscience](http://journal.frontiersin.org/article/10.3389/fncom.2016.00094/full)

[Random synaptic feedback weights support error backpropagation for deep learning (Feedback alignment)](https://www.nature.com/articles/ncomms13276#s1)
[Supplementary material](https://images.nature.com/original/nature-assets/ncomms/2016/161108/ncomms13276/extref/ncomms13276-s1.pdf)

[How Does the Sparse Memory “Engram” Neurons Encode the Memory of a Spatial–Temporal Event? (Exitory-Inhibitory)](https://www.frontiersin.org/articles/10.3389/fncir.2016.00061/full)

[Memory-based control with recurrent neural networks (RDPG)](http://rll.berkeley.edu/deeprlworkshop/papers/rdpg.pdf)

[Asynchrouous Methods for Deep Reinforcement Learning (A3C)](https://arxiv.org/pdf/1602.01783.pdf)

## 2015

[A Statistical View of Deep Learning](http://blog.shakirm.com/wp-content/uploads/2015/07/SVDL.pdf)

## 2014

[On the Number of Linear Regions of Deep Neural Networks (Relu)](https://arxiv.org/pdf/1402.1869.pdf)

[Network in Network (Global Average Pooling)](https://arxiv.org/pdf/1312.4400.pdf)

# Dessert 
[What is the statistical interpretation of NN - Quora (Regression equations)](https://www.quora.com/What-is-a-statistical-interpretation-of-neural-networks)

[RNN intro cs.toronto](http://www.cs.toronto.edu/~urtasun/courses/CSC2541_Winter17/RNN.pdf)

[14 DESIGN PATTERNS TO IMPROVE YOUR CONVOLUTIONAL NEURAL NETWORKS](https://www.topbots.com/14-design-patterns-improve-convolutional-neural-network-cnn-architecture/)

[Implementing Batch Normalization in Tensorflow](https://r2rt.com/implementing-batch-normalization-in-tensorflow.html)

[An Introduction to distributed Deep Learning](https://seba-1511.github.io/dist_blog/)

[Python Asynchrounous programming](https://www.youtube.com/watch?v=cYUr0BveIkY)

[How to deploy Machine Learning models with TensorFlow. Part 1 — make your model ready for serving.](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198)

[【TensorFlow】tf.nn.conv2d是怎样实现卷积的？](http://blog.csdn.net/mao_xiao_feng/article/details/78004522)

[【Tensorflow】tf.nn.separable_conv2d如何实现深度可分卷积?](http://blog.csdn.net/mao_xiao_feng/article/details/78002811)

[【Tensorflow】tf.nn.depthwise_conv2d如何实现深度卷积?](http://blog.csdn.net/mao_xiao_feng/article/details/78003476)

[【Tensorflow】tf.nn.atrous_conv2d如何实现空洞卷积？](http://blog.csdn.net/mao_xiao_feng/article/details/78003730)

[TensorFlow架构与设计：综述](http://www.jianshu.com/p/a5574ebcdeab)

[TensorFlow基本用法](https://yjango.gitbooks.io/superorganism/content/tensorflowji_ben_yong_fa.html)
